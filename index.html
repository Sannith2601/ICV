<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Anomaly Detection in Urban Video Surveillance</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 40px;
        }
        header, section {
            margin-bottom: 20px;
        }
        img {
            width: 100%; /* Adjust as needed */
            max-width: 600px; /* Adjust as needed */
            height: auto;
            margin: 10px 0;
        }
        .image-container {
            display: flex;
            justify-content: center;
        }
        .plot {
            display: block;
            margin: 20px auto;
        }
    </style>
</head>
<body>
    <header>
        <h1>Anomaly Detection in Urban Video Surveillance</h1>
    </header>

    <section>
        <h2>Introduction</h2>
        <p>As urban areas continue to expand, the complexity of maintaining safety and security grows exponentially. Motivated by this challenge, we chose to focus our project on anomaly detection in video surveillance, a critical component of modern urban security systems. Our interest in this field stems from its potential to significantly enhance the efficiency of monitoring public spaces. Below, we provide a couple of examples from our dataset that illustrate the typical urban scenes we analyze.</p>
        
    </section>

    <section>
        <h2>Method</h2>
        <h3>Our Approach</h3>
        <p>We employed a convolutional autoencoder, a deep learning model renowned for its ability to learn efficient data codifications in an unsupervised manner. This model was meticulously trained on a diverse dataset of normal surveillance footage to capture common patterns and activities in urban settings. By reconstructing the input video frames, the model was designed to pinpoint deviations from these learned patterns during its evaluation phase.</p>
        <h3>Implementation Details</h3>
        <ul>
            <li><strong>Frame Extraction:</strong> We extracted 200 uniformly spaced frames from each video, converting them to grayscale and resizing them to 224x224 pixels to maintain consistency.</li>
            <li><strong>Model Architecture:</strong> Our autoencoder features several layers of convolution for encoding and corresponding transposed convolution layers for decoding.</li>
            <li><strong>Training:</strong> We trained the model on 'normal' video frames, optimizing the reconstruction error using the Adam optimizer and binary cross-entropy loss.</li>
        </ul>
        <p>Example output images showing the side-by-side comparison of the original and reconstructed frames to highlight the modelâ€™s reconstruction capability.</p>
    </section>

    <section>
	<h2>Code</h2>
	<a href="cvi.pdf" target="_blank">View Code PDF</a>
<!-- Embedding the PDF -->
            <iframe src="cvi.pdf" width="100%" height="500px">
                <p>Your browser does not support iframes. You can <a href="import cv2.pdf">download the PDF here</a>.</p>
            </iframe>
        <h2>Results</h2>
        <h3>Anomaly Detection Performance</h3>
        <p>To assess the model's performance, we visualized the reconstruction errors, calculated as the mean squared error (MSE), across our test dataset. Frames with higher errors, which suggest potential anomalies, are flagged accordingly. Below is the plot that displays these errors over a sequence of test frames:</p>
        <img src="plot.png" alt="MSE Plot" class="plot">
    </section>

    <section>
        <h2>Analysis of Results</h2>
        <h3>Insights Gained</h3>
        <p>The analysis of MSE scores revealed that frames with abnormally high errors often correlated with unusual or unexpected activities, which were potential indicators of anomalies.</p>
        <h3>Surprising Findings</h3>
        <p>A notable observation was the model's sensitivity to varying lighting conditions, such as dynamic shadows, which were sometimes mistakenly identified as anomalies due to their significant visual difference from the norm.</p>
    </section>

    <section>
        <h2>Analysis of Vision Algorithms</h2>
        <p>The convolutional autoencoder demonstrated a commendable ability to detect deviations from typical patterns, underscoring its viability for this application. However, its effectiveness was somewhat dependent on the uniformity and quality of the training data.</p>
        <p>To improve accuracy, we strategically excluded night-time images from our training dataset. These images often introduced noise and inconsistencies that adversely affected the model
